# Running Q-Flood Locally with Docker

This guide explains how to run the **full Q-flood application** locally with all services (PostgreSQL, Redis, MinIO, Celery).

## ğŸ¯ Two Deployment Modes:

### 1. **Deployed Version** (Current - Railway/Vercel)
- âœ… Frontend: https://q-flood.vercel.app
- âœ… Backend: https://web-production-2d620.up.railway.app
- âš ï¸ Simplified (no Celery, Redis, MinIO)
- ğŸ“ For portfolio/CV demonstration

### 2. **Local Full Version** (Docker - This Guide)
- âœ… All services running (PostgreSQL, Redis, MinIO, Celery)
- âœ… Full job processing with background tasks
- âœ… File uploads and storage
- âœ… Complete geospatial features
- ğŸ”§ For development and testing

---

## ğŸ“‹ Prerequisites

1. **Docker Desktop** installed and running
   - Windows: https://www.docker.com/products/docker-desktop/
   - Check: `docker --version` should show version 20.10+

2. **Docker files exist locally** (not in git)
   - `Dockerfile`
   - `docker-compose.yml`
   - Both files are ignored by git to keep deployment simple

---

## ğŸš€ Quick Start

### Step 1: Ensure Docker Desktop is Running
```powershell
# Check Docker is running
docker ps

# Should show: "CONTAINER ID   IMAGE   ..."
# If error: Start Docker Desktop application
```

### Step 2: Start All Services
```powershell
cd c:\Users\adamf\Desktop\pp\repositories\q-flood

# Build and start all services (first time takes 5-10 minutes)
docker-compose up --build -d

# Check status
docker-compose ps
```

### Step 3: Wait for Services to Initialize
```powershell
# Watch logs until you see "Application startup complete"
docker-compose logs -f backend

# Press Ctrl+C to stop watching logs
```

### Step 4: Access the Application
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **MinIO Console**: http://localhost:9001 (login: minioadmin/minioadmin)

---

## ğŸ“¦ What Gets Started

| Service | Port | Description |
|---------|------|-------------|
| **PostgreSQL** | 5432 | Database with PostGIS extension |
| **Redis** | 6379 | Message broker for Celery |
| **MinIO** | 9000, 9001 | S3-compatible object storage |
| **Backend API** | 8000 | FastAPI with quantum/classical solvers |
| **Celery Worker** | - | Background job processor |
| **Frontend** | 5173 | React UI with map visualization |

---

## ğŸ§ª Testing the Full Application

### 1. Check Backend Health
```powershell
# Should return: {"message": "Welcome to Q-Flood API"}
curl http://localhost:8000
```

### 2. View API Documentation
Open in browser: http://localhost:8000/docs

### 3. Create a Test Job
Use the API docs at `/docs` or create a script:

```python
import requests

job = requests.post("http://localhost:8000/api/v1/jobs/", json={
    "name": "Test Quantum Job",
    "solver_type": "quantum",
    "geojson": {
        "type": "FeatureCollection",
        "features": [...]
    }
})

print(job.json())
```

### 4. View Job Processing
```powershell
# Watch Celery worker logs
docker-compose logs -f celery_worker

# Watch backend logs
docker-compose logs -f backend
```

---

## ğŸ› ï¸ Common Commands

### Start Services
```powershell
docker-compose up -d          # Start in background
docker-compose up             # Start with logs visible
```

### Stop Services
```powershell
docker-compose down           # Stop all services
docker-compose down -v        # Stop and remove volumes (clean database)
```

### View Logs
```powershell
docker-compose logs           # All services
docker-compose logs backend   # Specific service
docker-compose logs -f        # Follow (live)
```

### Restart a Service
```powershell
docker-compose restart backend
docker-compose restart celery_worker
```

### Rebuild After Code Changes
```powershell
docker-compose up --build -d
```

---

## ğŸ”§ Troubleshooting

### Docker Desktop Not Running
```
Error: Cannot connect to the Docker daemon
```
**Solution:** Start Docker Desktop application

### Port Already in Use
```
Error: port is already allocated
```
**Solution:** Stop conflicting service or change port in `docker-compose.yml`

### Services Keep Restarting
```powershell
# Check what's wrong
docker-compose logs backend
docker-compose logs celery_worker
```

### Database Connection Issues
```powershell
# Reset database
docker-compose down -v
docker-compose up -d
```

### Need Fresh Start
```powershell
# Nuclear option: remove everything and start fresh
docker-compose down -v
docker system prune -a
docker-compose up --build -d
```

---

## ğŸ†š Local vs Deployed Versions

| Feature | Local (Docker) | Deployed (Railway/Vercel) |
|---------|----------------|---------------------------|
| **Frontend UI** | âœ… Full | âœ… Full |
| **Backend API** | âœ… Full | âœ… Full |
| **Quantum Solver** | âœ… Works | âœ… Works |
| **Classical Solver** | âœ… Works | âœ… Works |
| **Background Jobs** | âœ… Works (Celery) | âŒ No Celery |
| **File Storage** | âœ… Works (MinIO) | âŒ No MinIO |
| **Database** | âœ… PostgreSQL + PostGIS | âœ… SQLite |
| **Geospatial Features** | âœ… Full | âš ï¸ Limited |
| **Cost** | Free (local) | Free (tier limits) |
| **Internet Required** | âŒ No | âœ… Yes |

---

## ğŸ“ Development Workflow

1. **Make code changes** in `backend/` or `frontend/`
2. **Rebuild and restart**:
   ```powershell
   docker-compose up --build -d
   ```
3. **Test changes** at http://localhost:5173
4. **View logs** if something breaks:
   ```powershell
   docker-compose logs -f
   ```

---

## ğŸ¯ When to Use Which Version

### Use **Local Docker** when:
- âœ… Developing new features
- âœ… Testing full job processing
- âœ… Need file uploads
- âœ… Testing geospatial features
- âœ… Debugging background tasks

### Use **Deployed Version** when:
- âœ… Showing to recruiters/employers
- âœ… Adding to CV/portfolio
- âœ… Quick demos
- âœ… Testing frontend UI only

---

## ğŸ” Environment Variables

The `.env` file contains Docker service names:
- `DATABASE_URL=postgresql://user:password@db:5432/flood_db`
- `REDIS_URL=redis://redis:6379/0`
- `MINIO_ENDPOINT=minio:9000`

These work because Docker Compose creates a network where services can find each other by name.

---

## ğŸ“š Next Steps

1. âœ… Start Docker Desktop
2. âœ… Run `docker-compose up -d`
3. âœ… Wait for services to start
4. âœ… Open http://localhost:5173
5. âœ… Test creating a job
6. âœ… Check Celery processes it
7. ğŸ‰ Full Q-flood working locally!

---

## â“ Questions?

Check the main README.md for general info, or:
- View logs: `docker-compose logs -f`
- Check service status: `docker-compose ps`
- Restart everything: `docker-compose restart`

Your deployed version at https://q-flood.vercel.app is separate and unaffected by local Docker setup!
